# 🧠 RAG（检索增强生成）

**个人积累项目 — Filly Minghao LUO**

RAG（Retrieval-Augmented Generation，检索增强生成）通过结合**外部知识检索**来增强**大语言模型（LLMs）**的能力。  
它会从向量数据库中检索出与问题最相关的信息，并与用户的问题结合，从而生成**准确、可靠、可解释**的回答。  
非常适合用于 **问答系统（Q&A）**、**聊天机器人（Chatbot）** 以及 **知识库系统（Knowledge-based Systems）**。

---

## 🔹 Embedding 模型简介

**Embedding 模型**用于判断一段文字与用户问题之间的语义相关性。

- 输入：一段文本  
- 输出：固定长度的向量表示  
- 向量是语义压缩的结果，保留核心含义但省略细节  
- 相似的文本，其向量距离更接近，可用于判断语义相似度  
- 实际中向量维度通常在 **1000~3000**  
- 用户问题也会被嵌入成向量，与数据库中的文本向量进行相似度匹配，从而找到最相关的信息

---

## 🔹 Chunking：AI 如何处理长文档

当文档过长时，RAG 会将其切分成多个更小的 **chunk（文本块）** 以便更好地检索和推理。

常见的切分方式包括：
- 按 **字数** 切分  
- 按 **句子** 切分  
- 按 **段落** 切分  

每个切分后的文本块都会被转换成向量并存储在**向量数据库（Vector Database）**中，以便快速相似检索。

---

## 🔹 常见的向量数据库

- 🪶 **Pinecone**  
- 💾 **Chroma**  
- 🧩 **PostgreSQL (pgvector)**  

这些数据库支持高效的相似度检索：输入一个向量即可找到与之最接近的文本片段。

---

## 🔹 RAG 工作流程

1. 用户输入一个问题  
2. 将问题通过 Embedding 模型转化为向量  
3. 从向量数据库中检索出最相似的若干文本块  
4. 将这些文本与问题一起发送给大语言模型生成回答  

➡️ 这就是完整的 **RAG 流程：Retrieval → Augmentation → Generation**

---

## ⚠️ RAG 的局限性

1. **切分策略问题**：不同文档结构差异较大，无法用统一的切分方式适配所有场景，关键语句可能被截断。  
2. **缺乏全局视野**：模型只能看到被检索到的局部内容，无法理解整篇文章的上下文。

---

## 🧩 改进方向

- 明确人称代词，将“你、我、他”等替换为具体的实体名称  
- 让大语言模型参与**语义切分（Semantic Chunking）**，使 chunk 更符合语义边界  

---

## 📘 总结

本仓库是一个 **个人积累与实验项目**，旨在探索 RAG 架构的具体实现。  
通过结合 **Embedding 模型**、**向量数据库** 与 **大语言模型**，展示了检索增强方法如何提升 AI 回答的准确性与事实可靠性。  

---

_✨ 作者：Filly Minghao LUO — 个人 RAG 学习与实践项目。_
